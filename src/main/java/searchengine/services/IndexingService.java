package searchengine.services;

import org.apache.lucene.morphology.LuceneMorphology;
import org.apache.lucene.morphology.english.EnglishLuceneMorphology;
import org.apache.lucene.morphology.russian.RussianLuceneMorphology;
import org.jsoup.Jsoup;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;

import org.springframework.transaction.annotation.Propagation;
import searchengine.config.SitesList;
import searchengine.model.*;
import searchengine.repository.PageRepository;
import searchengine.repository.SiteRepository;

import java.io.IOException;
import java.time.LocalDateTime;
import java.util.*;
import searchengine.repository.LemmaRepository;
import searchengine.repository.IndexRepository;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.TimeUnit;
import org.springframework.transaction.annotation.Transactional;
import java.util.concurrent.ConcurrentHashMap;
import org.springframework.context.annotation.Lazy;

@Lazy
@Service

public class IndexingService {

    private static final Logger logger = LoggerFactory.getLogger(IndexingService.class);
    private final ConcurrentHashMap<String, Boolean> indexingTasks = new ConcurrentHashMap<>();
    private final SitesList sitesList;
    private final SiteRepository siteRepository;
    private final PageRepository pageRepository;
    private final LemmaRepository lemmaRepository;
    private final IndexRepository indexRepository;

    private volatile boolean indexingInProgress = false;
    private ExecutorService executorService;
    private ForkJoinPool forkJoinPool;

    public IndexingService(SitesList sitesList,LemmaRepository lemmaRepository, IndexRepository indexRepository, SiteRepository siteRepository,  PageRepository pageRepository ) {
        this.sitesList = sitesList;
        this.siteRepository = siteRepository;
        this.pageRepository = pageRepository;
        this.indexRepository = indexRepository;
        this.lemmaRepository = lemmaRepository;

    }

    public synchronized boolean isIndexingInProgress() {
        return indexingInProgress;
    }

    public synchronized void startFullIndexing() {
        if (indexingInProgress) {
            logger.warn("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.");
            throw new IllegalStateException("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞.");
        }
        indexingInProgress = true;
        logger.info("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–∞—á–∞—Ç–∞.");

        executorService = Executors.newSingleThreadExecutor();
        executorService.submit(() -> {
            try {
                performIndexing();
            } catch (Exception e) {
                logger.error("–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: ", e);
            } finally {
                indexingInProgress = false;
                logger.info("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.");
            }
        });
        executorService.shutdown();
    }

    public synchronized void stopIndexing() {
        if (!indexingInProgress) {
            logger.warn("–ü–æ–ø—ã—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è.");
            return;
        }
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.");
        indexingInProgress = false;

        if (executorService != null) {
            executorService.shutdownNow();
        }
        if (forkJoinPool != null) {
            forkJoinPool.shutdownNow();
        }

        updateSitesStatusToFailed("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º");
    }


    private void performIndexing() {
        List<searchengine.config.ConfigSite> sites = sitesList.getSites();
        if (sites == null || sites.isEmpty()) {
            logger.warn("–°–ø–∏—Å–æ–∫ —Å–∞–π—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—É—Å—Ç.");
            return;
        }

        executorService = Executors.newFixedThreadPool(sites.size());
        try {
            for (searchengine.config.ConfigSite site : sites) {
                // Ensure we only index sites from the configured list
                if (isConfiguredSite(site.getUrl())) {
                    executorService.submit(() -> {
                        logger.info("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å–∞–π—Ç–∞: {} ({})", site.getName(), site.getUrl());
                        startIndexingForSite(site.getUrl()); // Add the site to active tasks
                        try {
                            deleteSiteData(site.getUrl());
                            searchengine.model.Site newSite = new searchengine.model.Site();
                            newSite.setName(site.getName());
                            newSite.setUrl(site.getUrl());
                            newSite.setStatus(IndexingStatus.INDEXING);
                            newSite.setStatusTime(LocalDateTime.now());
                            siteRepository.save(newSite);

                            // Crawl and index the pages for the site
                            PageCrawler.startCrawling(
                                    newSite,
                                    site.getUrl(),
                                    lemmaRepository,
                                    siteRepository,
                                    indexRepository,
                                    pageRepository,
                                    this  // Pass the current instance of IndexingService
                            );

                            if (indexingInProgress) {
                                updateSiteStatusToIndexed(newSite);
                            } else {
                                logger.warn("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞. –°—Ç–∞—Ç—É—Å —Å–∞–π—Ç–∞ {} –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ INDEXED.", site.getName());
                            }
                        } catch (Exception e) {
                            handleIndexingError(site.getUrl(), e);
                        } finally {
                            stopIndexingForSite(site.getUrl()); // Remove the site from active tasks
                        }
                    });
                } else {
                    logger.warn("–°–∞–π—Ç {} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.", site.getUrl());
                }
            }
        } finally {
            executorService.shutdown();
            try {
                if (!executorService.awaitTermination(1, TimeUnit.HOURS)) {
                    executorService.shutdownNow();
                    logger.error("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.");
                }
            } catch (InterruptedException e) {
                executorService.shutdownNow();
                logger.error("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –±—ã–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞: {}", e.getMessage());
                Thread.currentThread().interrupt();
            }
        }
    }

    private boolean isConfiguredSite(String url) {
        List<searchengine.config.ConfigSite> sites = sitesList.getSites();
        for (searchengine.config.ConfigSite site : sites) {
            if (site.getUrl().equals(url)) {
                return true;
            }
        }
        return false;
    }



    @Transactional
    private void deleteSiteData(String siteUrl) {
        searchengine.model.Site site = siteRepository.findByUrl(siteUrl);
        if (site != null) {
            Long siteId = (long) site.getId();

            int indexesDeleted = indexRepository.deleteBySiteId(site.getId());

            int lemmasDeleted = lemmaRepository.deleteBySiteId(siteId);

            int pagesDeleted = pageRepository.deleteAllBySiteId(site.getId());

            siteRepository.delete(site);

            logger.info("–£–¥–∞–ª–µ–Ω–æ {} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã index.", indexesDeleted);
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã lemma.", lemmasDeleted);
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã page –¥–ª—è —Å–∞–π—Ç–∞ {}.", pagesDeleted, siteUrl);
            logger.info("–°–∞–π—Ç {} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω.", siteUrl);
        } else {
            logger.warn("–°–∞–π—Ç {} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.", siteUrl);
        }
    }

    private void updateSiteStatusToIndexed(searchengine.model.Site site) {
        if (site.getStatus() == IndexingStatus.FAILED) {
            logger.warn("–°–∞–π—Ç {} –∏–º–µ–µ—Ç –æ—à–∏–±–∫—É, —Å—Ç–∞—Ç—É—Å INDEXED –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è.", site.getUrl());
            return;
        }

        site.setStatus(IndexingStatus.INDEXED);
        site.setStatusTime(LocalDateTime.now());
        siteRepository.save(site);
        logger.info("–°–∞–π—Ç {} –∏–∑–º–µ–Ω–∏–ª —Å—Ç–∞—Ç—É—Å –Ω–∞ INDEXED.", site.getUrl());
    }


    private void handleIndexingError(String siteUrl, Exception e) {
        searchengine.model.Site site = siteRepository.findByUrl(siteUrl);
        if (site != null) {
            site.setStatus(IndexingStatus.FAILED);
            site.setLastError(e.getMessage());
            site.setStatusTime(LocalDateTime.now());
            siteRepository.save(site);
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —Å–∞–π—Ç–∞ {}: {}", site.getUrl(), e.getMessage());
        }
    }

    private void updateSitesStatusToFailed(String errorMessage) {
        List<searchengine.model.Site> sites = siteRepository.findAllByStatus(IndexingStatus.INDEXING);
        for (searchengine.model.Site site : sites) {
            site.setStatus(IndexingStatus.FAILED);
            site.setLastError(errorMessage);
            site.setStatusTime(LocalDateTime.now());
            siteRepository.save(site);
            logger.info("–°–∞–π—Ç {} –∏–∑–º–µ–Ω–∏–ª —Å—Ç–∞—Ç—É—Å –Ω–∞ FAILED: {}", site.getUrl(), errorMessage);
        }
    }

    private void startIndexingForSite(String url) {
        indexingTasks.put(url, true);
    }

    private void stopIndexingForSite(String url) {
        indexingTasks.remove(url);
    }

    public boolean isSiteIndexing(String url) {
        return indexingTasks.getOrDefault(url, false);
    }

    public boolean checkAndUpdateStatus(String message) {
        if (!indexingInProgress) {
            logger.warn("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {}", message);
            return false;
        }
        return true;
    }

    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void processPageContent(Page page) {
        try {
            String text = extractTextFromHtml(page.getContent());
            Map<String, Integer> lemmas = lemmatizeText(text);

            Set<String> processedLemmas = new HashSet<>();
            List<Lemma> lemmasToSave = new ArrayList<>();
            List<Index> indexesToSave = new ArrayList<>();

            for (Map.Entry<String, Integer> entry : lemmas.entrySet()) {
                String lemmaText = entry.getKey();
                int count = entry.getValue();

                logger.info("üî§ –ù–∞–π–¥–µ–Ω–∞ –ª–µ–º–º–∞: '{}', —á–∞—Å—Ç–æ—Ç–∞: {}", lemmaText, count);

                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –ª–µ–º–º–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
                if (!processedLemmas.add(lemmaText)) {
                    // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ª–µ–º–º—É, –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
                    logger.info("–õ–µ–º–º–∞ '{}' —É–∂–µ –±—ã–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.", lemmaText);
                    continue;
                }

                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —ç—Ç–∞ –ª–µ–º–º–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                Optional<Lemma> existingLemmaOpt = lemmaRepository.findByLemmaAndSite(lemmaText, page.getSite());
                if (existingLemmaOpt.isPresent()) {
                    // –õ–µ–º–º–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –æ–±–Ω–æ–≤–ª—è–µ–º –µ—ë —á–∞—Å—Ç–æ—Ç—É
                    Lemma existingLemma = existingLemmaOpt.get();
                    existingLemma.setFrequency(existingLemma.getFrequency() + count);  // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
                    lemmasToSave.add(existingLemma);  // –î–æ–±–∞–≤–ª—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –ª–µ–º–º—É
                    logger.info("–õ–µ–º–º–∞ '{}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö, –æ–±–Ω–æ–≤–ª—è–µ–º —á–∞—Å—Ç–æ—Ç—É.", lemmaText);
                    continue;  // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –ª–µ–º–º—ã
                }

                // –ï—Å–ª–∏ –ª–µ–º–º–∞ –Ω–æ–≤–∞—è, —Å–æ–∑–¥–∞—ë–º –µ—ë
                Lemma lemma = new Lemma(null, page.getSite(), lemmaText, count);  // –ó–∞–¥–∞—ë–º –Ω–∞—á–∞–ª—å–Ω—É—é —á–∞—Å—Ç–æ—Ç—É
                lemmasToSave.add(lemma);

                // –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å
                Index index = new Index(null, page, lemma, (float) count);
                indexesToSave.add(index);
            }

            // –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –∏–ª–∏ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –ª–µ–º–º—ã –∏ –∏–Ω–¥–µ–∫—Å—ã
            if (!lemmasToSave.isEmpty()) {
                lemmaRepository.saveAll(lemmasToSave);
            }

            if (!indexesToSave.isEmpty()) {
                indexRepository.saveAll(indexesToSave);
            }

        } catch (IOException e) {
            // –ü—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {}", page.getPath(), e);
        } catch (Exception e) {
            // –õ–æ–≤–∏–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏ –ª–æ–≥–∏—Ä—É–µ–º –∏—Ö
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ª–µ–º–º –∏ –∏–Ω–¥–µ–∫—Å–æ–≤: {}", e.getMessage(), e);
        }
    }

    private String extractTextFromHtml(String html) {
        return Jsoup.parse(html).text();
    }


    private Map<String, Integer> lemmatizeText(String text) throws IOException {
        Map<String, Integer> lemmaFrequencies = new HashMap<>();

        LuceneMorphology russianMorph = new RussianLuceneMorphology();
        LuceneMorphology englishMorph = new EnglishLuceneMorphology();

        String[] words = text.toLowerCase().split("\\P{L}+");

        for (String word : words) {
            if (word.length() < 2) continue;

            List<String> normalForms;
            if (word.matches("[–∞-—è—ë]+")) {
                normalForms = russianMorph.getNormalForms(word);
            } else if (word.matches("[a-z]+")) {
                normalForms = englishMorph.getNormalForms(word);
            } else {
                continue;
            }

            for (String lemma : normalForms) {
                lemmaFrequencies.put(lemma, lemmaFrequencies.getOrDefault(lemma, 0) + 1);
            }
        }

        return lemmaFrequencies;
    }
}
